---
title: "Bank Marketing Project"
author: "John Vincent Landingin"
date: "11/15/2021"
output: pdf_document
---

\tableofcontents 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Libraries, include=FALSE}
# The following libraries are used for the study.
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(ggpubr)) install.packages("ggpubr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
```

```{r Import dataset, include=FALSE}
dat <- read.csv(file = "bank-full.csv", header = T, sep = ";")
```


# Introduction  

The goal in this project is to create an algorithm that will predict whether a client will subscribe to a bank term deposit. The data used is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. The dataset was collected from the following website - https://archive.ics.uci.edu/ml/datasets/bank+marketing.

In the dataset, there are 45211 instances and 16 attributes/variables. The output variable is binary which is if the client subscribed or not to a term deposit in the marketing campaign.

Below are the variables.

Input variables:  
1 - age (numeric)  
2 - job : type of job (categorical:"admin.","unknown","unemployed","management","housemaid","entrepreneur","student","blue-collar","self-employed","retired","technician","services")   
3 - marital : marital status (categorical: "married","divorced","single"; note: "divorced" means divorced or widowed)  
4 - education (categorical: "unknown","secondary","primary","tertiary")  
5 - default: has credit in default? (binary: "yes","no")  
6 - balance: average yearly balance, in euros (numeric)   
7 - housing: has housing loan? (binary: "yes","no")  
8 - loan: has personal loan? (binary: "yes","no")  
9 - contact: contact communication type (categorical: "unknown","telephone","cellular")   
10 - day: last contact day of the month (numeric)  
11 - month: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")  
12 - duration: last contact duration, in seconds (numeric)  
13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  
14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)  
15 - previous: number of contacts performed before this campaign and for this client (numeric)   
16 - poutcome: outcome of the previous marketing campaign (categorical: "unknown","other","failure","success")  

Output variable (desired target):  
17 - y - has the client subscribed a term deposit? (binary: "yes","no")

Data exploration and visualization is done to check for each input variable on whether or how they may be used for building the algorithm. This gives a general idea for the dataset. Then for the modeling approach, both logistics regression and random forest is done. The former is done for benchmark purposes to compare whether a more complex model like Random Forest is necessary.

# Analysis  

## Data Exploration and Visualization  
For this section, we explore our variables and look for insights that could help in creating our model 
in predicting whether a client will subscribe to a term deposit after a campaign.

### Demographic Profile

#### Subscribers (y)
To get an initial idea, below is the distribution of clients who subscribed and did not subscribed.  

```{r echo=FALSE}
dat %>%
  mutate(prop = round(ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),2),
         prop = percent(prop),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 2000)) %>%
  ggplot(aes(x = y, fill = y)) +
  geom_bar() +
  geom_text(aes(label = paste0("count: ",count," ", "percent: ", prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count")

```
Overall, 5289 clients subscribed from the campaign, which is 12% of the total clients contacted during the campaign.

#### Age  
```{r echo=FALSE}
summary(dat$age)
```
The minimum age in the data is 18, while the maximum age is 95. The Median age is 39.

```{r echo=FALSE, message=FALSE, warning=FALSE}
dat %>%
  mutate(ageGroup = ifelse(age %in% c(18:25), "18-25", 
                           ifelse(age %in% c(26:33), "26-33", 
                                  ifelse(age %in% c(34:41), "34-41",
                                         ifelse(age %in% c(34:41), "34-41",
                                                ifelse(age %in% c(42:49), "42-49",
                                                       ifelse(age %in% c(50:59), "50-59","60+"))))))) %>%
  ggplot(aes(ageGroup, fill = y)) +
  geom_bar() +
  ylab("Count") +
  xlab("Age Group") +
  ggtitle("Frequency of subscribers and non-subscribers among age groups")
```
Based from the plot, most of the subscribers are aged between 26-33 and 34-41, while least of the subscribers are 18-25 and 60+. 

```{r echo=FALSE}
fig1 <- dat %>%
  mutate(ageGroup = ifelse(age %in% c(18:25), "18-25", 
                           ifelse(age %in% c(26:33), "26-33", 
                                  ifelse(age %in% c(34:41), "34-41",
                                         ifelse(age %in% c(34:41), "34-41",
                                                ifelse(age %in% c(42:49), "42-49",
                                                       ifelse(age %in% c(50:59), "50-59","60+"))))))) %>%
  group_by(age, ageGroup) %>%
  summarize(count = n()) %>%
  ggplot(aes(age, count, fill = ageGroup)) +
  geom_col() +
  scale_x_continuous(breaks = seq(0, 90, 10)) +
  xlab("Age") +
  ylab("Count") +
  ggtitle("Age group sizes")

#Percent of clients that subscribed a term deposit by age group
fig2 <- dat %>%
  mutate(ageGroup = ifelse(age %in% c(18:25), "18-25", 
                           ifelse(age %in% c(26:33), "26-33", 
                                  ifelse(age %in% c(34:41), "34-41",
                                         ifelse(age %in% c(34:41), "34-41",
                                                ifelse(age %in% c(42:49), "42-49",
                                                       ifelse(age %in% c(50:59), "50-59","60+"))))))) %>%
  group_by(age, ageGroup) %>%
  summarize(prop = sum(y == "yes")/n()) %>%
  ggplot(aes(age, prop, fill = ageGroup)) +
  geom_col() +
  scale_x_continuous(breaks = seq(0, 90, 10)) +
  ylab("Subscribed (%)") +
  xlab("Age") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Proportion of subscribers among age groups")

ggarrange(fig2, fig1, ncol = 1, nrow = 2, common.legend = TRUE, legend = "bottom")
```
It can be seen from the plot that clients aged around 18-25 and 60+ are more likely to subscribe from a campaign but their group sizes are few which is why most subscribers are still aged between 26-33 as seen from the previous plot.

#### Job Group   


```{r echo=FALSE}
dat %>%
  group_by(job) %>%
  mutate(yesnum = sum(y == "yes"),
         yesprcnt = sum(y == "yes")/n()) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(job, yesnum), fill =y)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 40, hjust = 1)) +
  geom_text(aes(label = scales::percent(yesprcnt),
            y = yesnum/2),
            vjust = 0,
            size = 2) +
  xlab("Job Group") +
  ylab("Count")
```


Based from the plot, most of the clients called were blue-collar workers, but majority who subscribed
were working with management. Meanwhile, least of the subscribers were housemaids. With regards to
proportion of subscribers per job group, the student and retired were most likely to be subscribed with
28.7% and 22.8% of the group size, while blue-collar workers were least likely to be subscribed, with
only 7.28% of the group.

#### Marital Status  

```{r echo=FALSE}
dat %>%
  group_by(marital) %>%
  mutate(prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes"))) %>%
  ungroup() %>%
  ggplot(aes(x = marital, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0,
            size = 4) +
  ylab("count")
```

Based from the plot, majority of the subscribers are married, but only 10.1% of those married are subscribed. Moreover, single clients are more likely to be subscribers, comprising 14.9% of the single clients.

#### Education   

```{r echo=FALSE}
dat %>%
  group_by(education) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes"))) %>%
  ungroup() %>%
  ggplot(aes(x = education, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0,
            size = 4) +
  ylab("count")
```
Based from the plot, majority of the subscribers have secondary education level, but only 10.6% of those are subscribed. Furthermore, tertiary education level clients are more likely to be subscribers, comprising 15.0% of their group.

#### Default  
```{r echo=FALSE}
dat %>%
  group_by(default) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 4000)) %>%
  ungroup() %>%
  ggplot(aes(x = default, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count")
```
Based from the plot, majority of the subscribers do not have credit in default, and are also more likely to be subscribed comprising 11.8% of their group.

#### Loan   
```{r echo=FALSE}
fig3 <- dat %>%
  group_by(housing) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 2000)) %>%
  ungroup() %>%
  ggplot(aes(x = housing, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count") +
  ggtitle("Housing Loan") +
  ylim(0, 40000)

fig4 <- dat %>%
  group_by(loan) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 2000)) %>%
  ungroup() %>%
  ggplot(aes(x = loan, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count") +
  ggtitle("Personal Loan") +
  ylim(0, 40000)

ggarrange(fig3, fig4, nrow = 1, ncol = 2, common.legend = T, legend = "right")
```
Based from the plot, majority of the clients had a housing loan but majority of the clients that subscribed did not have a housing loan. Furthermore, majority of the clients do not have a personal loan. Majority of the clients who also subscribed do not have a personal loan.

#### Balance
```{r}
summary(dat$balance)
```
The minimum balance in the data is -8019 euros, while the maximum balance is 102127 euros.

```{r echo=FALSE}
dat %>%
  filter(balance < 25000) %>%
  select(balance, y) %>%
  ggplot(aes(balance, fill = y)) +
  geom_histogram(color = "black", bins = 50) +
  scale_x_continuous(breaks = seq(-5000,25000,5000))
```

We observe that most balances are between around -1000 euros to 10000 euros so we zoom a bit more in the graph below.  
```{r echo=FALSE}
dat %>%
  filter(balance < 10000, balance > -1000) %>%
  select(balance, y) %>%
  ggplot(aes(balance, fill = y)) +
  geom_histogram(color = "black", bins = 50) +
  scale_x_continuous(breaks = c(0,seq(-500,10000,1000)))
```

As observed from the graph, balanced of the clients are mostly between -500 euros to 1500 euros.
Summary statistic tells us that the median is 448 euros.

### Contact Details  

#### Contact  
```{r echo=FALSE}
dat %>%
  group_by(contact) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 1000)) %>%
  ungroup() %>%
  ggplot(aes(x = contact, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count")
```
Based from the graph, most of the clients contacted was by cellular. Most clients who also subscribed
were also contacted by cellular, having as well the highest proportion of the group size that subscribed (14.9%).

#### Date    
```{r echo=FALSE, message=FALSE, warning=FALSE}
fig5 <- dat %>%
  mutate(date = as.Date(paste0(month, day), "%B%d")) %>%
  ggplot(aes(x = date, fill =y)) +
  geom_histogram(color = "black") +
  ylab("count") +
  scale_x_date(date_breaks = "1 month", labels = date_format("%b")) +
  ggtitle("Bar Graph")


fig6 <- dat %>%
  mutate(date = as.Date(paste0(month, day), "%B%d")) %>%
  ggplot(aes(x = date, fill =y)) +
  geom_density(alpha = 0.5) +
  scale_x_date(date_breaks = "1 month", labels = date_format("%b")) +
  ggtitle("Density Plot")

ggarrange(fig5, fig6, nrow = 2, ncol = 1)
```

It seems that most of the clients are contacted between May to June. From the density plot,
it can be seen that most subscribers are also within those months, followed by from July to September.

```{r}
# Below we add date to the dataset
dat <- dat %>%
  mutate(date = as.Date(paste0(month, day), "%B%d")) %>%
  select(-month, -day)
```

#### Duration  
```{r}
summary(dat$duration)
```

```{r echo=FALSE}
dat %>%
  filter(duration < 1000) %>%
  mutate(duration = duration/60) %>%
  ggplot(aes(x = duration, fill =y)) +
  geom_histogram(color = "black", bins = 10) +
  scale_x_continuous(breaks = c(seq(0,100,1))) +
  xlab("duration (minutes)")
```
From the bar graph, it can be observed that most calls are between 2 minutes. But call above 3 minutes look to have higher rate of client subscription than below 2 mins.

### Campaign Details  

#### Campaign  

```{r}
summary(dat$campaign)
```
```{r}
sum(dat$campaign)
```

A total of 124956 contacts were made. The median number of contacts per client is 2.

####pdays  
```{r}
dat %>%
  filter(pdays > 0) %>%
  ggplot(aes(x = pdays, fill =y)) +
  geom_histogram(color = "black", bins = 50) +
  scale_x_continuous(breaks = c(0,100,200,300,400)) +
  coord_cartesian(xlim = c(-1, 400))
```
Clients contacted just around less than 100 days since last contact were the most common among
clients that were previously contacted. They also look to have highest subscriber to non-subscriber ratio.

It does not look like there is a significant pattern shown in pdays so we explore further the proportion
of subscribers in the below graph.  

```{r message=FALSE, warning=FALSE}
dat %>%
  group_by(pdays) %>%
  summarize(percent = mean(y == "yes")) %>%
  ggplot(aes(pdays, percent)) +
  geom_smooth() +
  geom_point(alpha = 0.2)
```
Upon inspection, pdays do not seem to uncover a much meaningful insight or possible generalization,
thus, this will not be used in building the algorithm.

#### previous  
```{r}
dat %>%
  group_by(previous) %>%
  filter(previous < 50) %>%
  summarize(percent = mean(y == "yes")) %>%
  ggplot(aes(previous, percent)) +
  geom_smooth() +
  geom_point()
```
Upon inspection, it looks like the more number of contacts performed before this campaign and for this client, the less likely they will subscribe. But the larger previous numbers vary very wisdely and looks to show a lot of noise. Thus, this will not be used.

#### poutcome

```{r}
dat %>%
  group_by(poutcome) %>%
  mutate(yesnum = sum(y == "yes"),
         prop = ifelse(y == "yes", sum(y == "yes")/n(), sum(y == "no")/n()),
         count = ifelse(y == "yes", sum(y == "yes"), sum(y == "no") + sum(y == "yes") + 2000)) %>%
  ungroup() %>%
  ggplot(aes(x = poutcome, fill =y)) +
  geom_bar() +
  geom_text(aes(label = scales::percent(prop),
                y = count/2,
                group = y),
            vjust = 0.5,
            size = 4) +
  ylab("count")
```
Based from the graph, most of the clients had unknown outcome from previous marketing campaign. But
upon inspection, a successful outcome from previous marketing campaign shows a better chance of their
subscription for a new campaign. Also,a previous failure shows the worst chance that they will subscribe.

To finalize, based from the data exploration, all input variables will be used to train the algorithm except for pdays and previous.

## Modeling  

In this section, we create an algorithm to predict if the client will subscribe a term deposit. The input variables will be used to train the algorithm.

First we divide the dataset into training and test sets with the code below. 20% of the data is the test set and the other 80% is the training set. The ratio 80/20 ratio was chosen, as opposed to 70/30 or 60/40, since the dataset is fairly large.
```{r}
test_index <- createDataPartition(y = dat$y, times = 1, p = 0.2, list = F)
train_set <- dat[-test_index,]
test_set <- dat[test_index,]
```


First, logistics regression is done below as a benchmark to compare as to whether a more complex model will be necessary.

#### Logistics Regression

```{r}
train_glm <- train(y ~ age + job + marital + education + default + balance + housing + loan + date +
                     contact + duration + campaign + poutcome, method = "glm", data = train_set, 
                   trControl = trainControl(method="cv", number = 5))
train_glm
```
The accuracy is fairly good with `r percent(train_glm$results$Accuracy, accuracy = 0.01)` accuracy.

#### Random Forest  

Below we run train a random forest algorithm. First we see what variables give highest importance and see if we can reduce the predictors. Also we use ntree = 150 and nsamp = 5000 to speed up runnnig the code for productivity purposes in tuning. 5-fold cross validation is also used.

```{r}
train_rf <- train(y ~ age + job + marital + education + default + balance + housing + loan + date +
                           contact + duration + campaign + poutcome, method = "rf", data = train_set,
                         ntree = 150,
                         trControl = trainControl(method="cv", number = 5),
                         tuneGrid = data.frame(mtry = c(1, 5, 10, 25, 50, 100)),
                         nsamp = 5000)
train_rf
```

Below is the variable importance values:

```{r}
varImp(train_rf)
```
varImp shows that only duration, date, balance, age, campaign, housing, and contact have importance values above 4. Below we rerun the code with variables having importance values above 4 and see how it affects accuracy.

```{r}
train_rf <- train(y ~ age + balance + housing  + date + contact + duration + campaign, 
                         method = "rf", 
                         data = train_set,
                         ntree = 150,
                         trControl = trainControl(method="cv", number = 5),
                         tuneGrid = data.frame(mtry = c(1, 5, 10, 25, 50, 100)),
                         nsamp = 5000)
train_rf
```

```{r}
varImp(train_rf)
```

Accuracy is a bit worse compared to using all variables. Below we try with variables having importances above 10 if accuracy is better:  

```{r}
train_rf <- train(y ~ age + balance  + date + duration + campaign, 
                         method = "rf", 
                         data = train_set,
                         ntree = 150,
                         trControl = trainControl(method="cv", number = 5),
                         tuneGrid = data.frame(mtry = c(1, 5, 10, 25, 50, 100)),
                         nsamp = 5000)
train_rf
```
Accuracy is worse now with lesser predictors, thus we stick with using all predictors in the original 
algorithm.

```{r}
train_rf <- train(y ~ age + job + marital + education + default + balance + housing + loan + date +
                           contact + duration + campaign + poutcome, method = "rf", data = train_set,
                         ntree = 150,
                         trControl = trainControl(method="cv", number = 5),
                         tuneGrid = data.frame(mtry = c(1, 5, 10, 25, 50, 100)),
                         nsamp = 5000)
train_rf
```

```{r}
data.frame(Method = "Logistic Regression", Accuracy = train_glm$results$Accuracy) %>%
  bind_rows(data.frame(Method = "Random Forest", Accuracy = max(train_rf$results$Accuracy)))
```


Upon checking, using random forest has a better accuracy than just using logistics regression. Thus we fit the final model using random forest.

## Fitting the Final Model  
```{r}
col_index_remove <- which(colnames(train_set) %in% c("pdays", "previous", "y"))
y_col_index <- which(colnames(train_set) == "y")

fit_rf <- randomForest(train_set[,-col_index_remove], factor(train_set[,y_col_index]),
                       minNode = train_rf$bestTune$mtry)
y_hat_fitrf <- predict(fit_rf, test_set[,-col_index_remove])
confusionMatrix(y_hat_fitrf, factor(test_set[,y_col_index]))
```

```{r}
plot(fit_rf)
```
Plot also shows that it look like we have used enough trees to get the best result out of the
random forest  

# Results 
Random Forest performed better than logistic regression during algorithm training, thus random forest was used to train the final model. All input variables were used except for pdays and previous. The final model performed with `r percent(confusionMatrix(y_hat_fitrf, factor(test_set[,y_col_index]))$overall[["Accuracy"]], accuracy = 0.01)` accuracy.

# Conclusion  
The goal in this project was to create an algorithm that will predict if a client will subscribe to a bank term deposit. Using all the variables except for pdays and previous, we were able to train an algorithm that can predict if a client will subscribe to a bank term deposit that performs with `r percent(confusionMatrix(y_hat_fitrf, factor(test_set[,y_col_index]))$overall[["Accuracy"]], accuracy = 0.01)` accuracy when evaluated with a test set. This model may be used for improving the marketing of the bank's products. For the limitations, the algorithm may be improved with more fine tuning with the parameters which can be done with faster computing power. Testing many other algorithm models then creating an Ensemble may also yield better results.
